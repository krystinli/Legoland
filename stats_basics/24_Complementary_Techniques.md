## Complementary_Techniques
When running experiments, you also need to generate ideas to test, create, and validate metrics, and establish evidence to support broader conclusions. Examples for techniques to complement and augment a healthy A/B testing culture:
- User experience research
- Focus groups
- Surveys
- Human evaluation
- Observational studies


## 01_Logs-based_Analysis
Retrospective analyses
- **Building intuition**: understand what is happening organically independent of experimentation, what size change might be pratically significant 
  - Distrbution of sessions per user or click through rate?
  - Difference by key segments such as country or platform
  - How do these distrbutions shift overtime?
  - How're users growing overtime? 
- **Characterizing potential metrics**: understand variance and distributions, how new metrics correlate with existing metrics
- **A/B test ideas**: 
  - Examine the conversion rate at each step of the purchase funnel to identify large drop offs
  - Analyze sessionized data can uncover that a particular action sequence took longer than expected 
  - This discover path leads to ideas of how to make your product better  

## 00_Quality_Research
- Ideas for experiments
  - Testing ideas that're easy to implement
  - Otherwise, use complementary techniques for early evaluation to reduce implementation cost   
- Validated metrics to measure the effects we care about
- Evidence supporting or refuting hypotheses, when running a controlled experinment is either not possible or sufficient
- Metrics complementary to the metrics computed from controlled experiments

**Trade-off**: generalizability vs. details we can get from lower-scale methods
- User Experience Research: high depth but low num of users
- Focus groups: similar to above
- Surveys: more people but medium depth
- Logs-based analysis: high num of users but low depth
- External data: potentially high dept and high num of users 
